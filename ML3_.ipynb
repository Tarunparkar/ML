{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNutZ88Va8w/IjoerKHPq1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tarunparkar/ML/blob/main/ML3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVCba-4D2jDA",
        "outputId": "fe4ad2d6-4b40-4270-85cb-a6b6c926bc37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data prepared.\n",
            "\n",
            "Vanilla Linear Regression:\n",
            " Train -> MSE: 21.6424, R²: 0.7509, Error %: 16.56%\n",
            " Test  -> MSE: 24.3385, R²: 0.6681, Error %: 16.89%\n",
            "\n",
            "L2 Regularization (Ridge):\n",
            " Train -> MSE: 21.6426, R²: 0.7509, Error %: 16.55%\n",
            " Test  -> MSE: 24.3402, R²: 0.6681, Error %: 16.89%\n",
            "\n",
            "L1 Regularization (Lasso):\n",
            " Train -> MSE: 22.1548, R²: 0.7450, Error %: 16.25%\n",
            " Test  -> MSE: 25.6748, R²: 0.6499, Error %: 17.30%\n",
            "\n",
            "ElasticNet (L1 + L2):\n",
            " Train -> MSE: 23.0175, R²: 0.7350, Error %: 16.28%\n",
            " Test  -> MSE: 25.9956, R²: 0.6455, Error %: 17.11%\n",
            "\n",
            "Summary of All Models:\n",
            "                           MSE Train  R2 Train  Error % Train   MSE Test  \\\n",
            "Model                                                                      \n",
            "Vanilla Linear Regression  21.642408  0.750874      16.557457  24.338532   \n",
            "L2 Regularization (Ridge)  21.642574  0.750872      16.553969  24.340177   \n",
            "L1 Regularization (Lasso)  22.154796  0.744976      16.245284  25.674811   \n",
            "ElasticNet (L1 + L2)       23.017466  0.735046      16.280294  25.995567   \n",
            "\n",
            "                            R2 Test  Error % Test  \n",
            "Model                                              \n",
            "Vanilla Linear Regression  0.668113     16.892706  \n",
            "L2 Regularization (Ridge)  0.668091     16.891054  \n",
            "L1 Regularization (Lasso)  0.649891     17.295394  \n",
            "ElasticNet (L1 + L2)       0.645517     17.109458  \n"
          ]
        }
      ],
      "source": [
        "# Step 1: Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 2: Load Boston Housing dataset\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "\n",
        "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "y = raw_df.values[1::2, 2]\n",
        "\n",
        "# Step 3: Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Add bias term (intercept)\n",
        "X_train_scaled = np.c_[np.ones(X_train_scaled.shape[0]), X_train_scaled]\n",
        "X_test_scaled = np.c_[np.ones(X_test_scaled.shape[0]), X_test_scaled]\n",
        "\n",
        "print(\"Data prepared.\")\n",
        "\n",
        "# Step 5: Evaluation function\n",
        "def evaluate_model(X_train, y_train, X_test, y_test, theta, model_name=\"Model\"):\n",
        "    y_train_pred = X_train @ theta\n",
        "    y_test_pred = X_test @ theta\n",
        "\n",
        "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "    r2_train = r2_score(y_train, y_train_pred)\n",
        "    error_train = np.mean(np.abs((y_train - y_train_pred) / y_train)) * 100\n",
        "\n",
        "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "    error_test = np.mean(np.abs((y_test - y_test_pred) / y_test)) * 100\n",
        "\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\" Train -> MSE: {mse_train:.4f}, R²: {r2_train:.4f}, Error %: {error_train:.2f}%\")\n",
        "    print(f\" Test  -> MSE: {mse_test:.4f}, R²: {r2_test:.4f}, Error %: {error_test:.2f}%\")\n",
        "\n",
        "    return {\n",
        "        \"Model\": model_name,\n",
        "        \"MSE Train\": mse_train,\n",
        "        \"R2 Train\": r2_train,\n",
        "        \"Error % Train\": error_train,\n",
        "        \"MSE Test\": mse_test,\n",
        "        \"R2 Test\": r2_test,\n",
        "        \"Error % Test\": error_test,\n",
        "    }\n",
        "\n",
        "# Step 6: Gradient Descent implementations\n",
        "\n",
        "def gradient_descent_vanilla(X, y, lr=0.01, n_iters=5000):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * X.T @ error\n",
        "        theta -= lr * gradients\n",
        "    return theta\n",
        "\n",
        "def gradient_descent_l2(X, y, lr=0.01, n_iters=5000, lambda_=0.1):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * (X.T @ error + lambda_ * np.r_[0, theta[1:]])  # Don't regularize bias\n",
        "        theta -= lr * gradients\n",
        "    return theta\n",
        "\n",
        "def gradient_descent_l1(X, y, lr=0.01, n_iters=5000, lambda_=0.1):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * X.T @ error\n",
        "        gradients[1:] += lambda_ * np.sign(theta[1:])\n",
        "        theta -= lr * gradients\n",
        "    return theta\n",
        "\n",
        "def gradient_descent_elasticnet(X, y, lr=0.01, n_iters=5000, lambda1=0.1, lambda2=0.1):\n",
        "    m, n = X.shape\n",
        "    theta = np.zeros(n)\n",
        "    for _ in range(n_iters):\n",
        "        y_pred = X @ theta\n",
        "        error = y_pred - y\n",
        "        gradients = (1/m) * X.T @ error\n",
        "        gradients[1:] += lambda1 * np.sign(theta[1:]) + lambda2 * theta[1:]\n",
        "        theta -= lr * gradients\n",
        "    return theta\n",
        "\n",
        "# Step 7: Train and evaluate all models\n",
        "\n",
        "results = []\n",
        "\n",
        "# Vanilla Linear Regression\n",
        "theta_vanilla = gradient_descent_vanilla(X_train_scaled, y_train)\n",
        "results.append(evaluate_model(X_train_scaled, y_train, X_test_scaled, y_test, theta_vanilla, \"Vanilla Linear Regression\"))\n",
        "\n",
        "# L2 (Ridge)\n",
        "theta_l2 = gradient_descent_l2(X_train_scaled, y_train, lambda_=0.1)\n",
        "results.append(evaluate_model(X_train_scaled, y_train, X_test_scaled, y_test, theta_l2, \"L2 Regularization (Ridge)\"))\n",
        "\n",
        "# L1 (Lasso)\n",
        "theta_l1 = gradient_descent_l1(X_train_scaled, y_train, lambda_=0.1)\n",
        "results.append(evaluate_model(X_train_scaled, y_train, X_test_scaled, y_test, theta_l1, \"L1 Regularization (Lasso)\"))\n",
        "\n",
        "# ElasticNet (L1 + L2)\n",
        "theta_elastic = gradient_descent_elasticnet(X_train_scaled, y_train, lambda1=0.1, lambda2=0.1)\n",
        "results.append(evaluate_model(X_train_scaled, y_train, X_test_scaled, y_test, theta_elastic, \"ElasticNet (L1 + L2)\"))\n",
        "\n",
        "# Step 8: Summary table\n",
        "results_df = pd.DataFrame(results).set_index(\"Model\")\n",
        "print(\"\\nSummary of All Models:\")\n",
        "print(results_df)\n"
      ]
    }
  ]
}